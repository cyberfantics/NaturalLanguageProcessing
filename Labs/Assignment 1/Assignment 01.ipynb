{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2467d594-f76e-46fc-abc9-cdccc0b32fc7",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ffcc00; background-color: #2a2a2a; padding: 30px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    Natural Language Processing\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ff9900; background-color: #333333; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    Lab 01\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ff6600; background-color: #1c1c1c; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    Syed Mansoor ul Hassan Bukhari\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ffcc00; background-color: #222222; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    BSAI - VII\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ff3300; background-color: #1c1c1c; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\">\n",
    "    2021-25\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #3399ff; background-color: #1c1c1c; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\">\n",
    "    <span style=\"position: relative; top: -10px;\">09</span> Dec, 2024\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da5dd2-b1dd-4623-a718-50a4e45a4ef9",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <br>\n",
    "    <strong style=\"color: #003366;\">Task 1: Data Cleaning</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">Remove the following elements from the input text:</span>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li>1. Hashtags (#) </li>\n",
    "        <li>2. Punctuation marks (e.g., commas, periods, exclamation marks, etc.)</li>\n",
    "        <li>3. Numbers (digits 0-9)</li>\n",
    "    </ul>\n",
    "    <span style=\"color: #333333;\">You can use regular expressions to perform these tasks. The goal is to clean the text, making it ready for further processing like tokenization and stemming/lemmatization.</span>\n",
    "    <br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c66c659-da6f-4492-855d-811bf9514a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "303558a1-0f7b-4808-96f2-0ca384607d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Remove hashtags, numbers, and punctuation marks using regular expressions\n",
    "    cleaned_text = re.sub(r'#\\S+', '', text)  # Remove hashtags\n",
    "    cleaned_text = re.sub(r'\\d+', '', cleaned_text)  # Remove numbers\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)  # Remove punctuation marks\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba968439-e8aa-4f1a-ac3d-009f061f9d8f",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Key Takeaways:</strong>\n",
    "    <br>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li><strong>#\\S+</strong>: Matches hashtags like <code>#Python</code> and <code>#AI</code>.</li>\n",
    "        <li><strong>[^\\w\\s]</strong>: Removes punctuation and special characters from the text.</li>\n",
    "        <li><strong>\\d+</strong>: Matches digits (numbers).</li>\n",
    "        <li><strong>\\s+</strong>: Matches any sequence of whitespace characters.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa76ffa7-f4c2-4454-a6ca-3dffa8e03c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = \"Hello world, This Is Mansoor. In BS (Artificial Intelligence). Are you interested in AI? #machine_learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b48c940c-4150-41a5-8697-8560cd4bc1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world This Is Mansoor In BS Artificial Intelligence Are you interested in AI '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess_text(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9ef256-0201-4e92-b13a-82fe560d4a24",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">>\r\n",
    "    <strong style=\"color: #003366;\">Regex Table</strong>\r\n",
    "    <br>\r\n",
    "    <table style=\"width: 100%; border-collapse: collapse; border: 1px solid #ddd;\">\r\n",
    "        <thead>\r\n",
    "            <tr>\r\n",
    "                <th style=\"padding: 12px; background-color: #003366; color: white; text-align: left;\">Pattern</th>\r\n",
    "                <th style=\"padding: 12px; background-color: #003366; color: white; text-align: left;\">Description</th>\r\n",
    "                <th style=\"padding: 12px; background-color: #003366; color: white; text-align: left;\">Example</th>\r\n",
    "                <th style=\"padding: 12px; background-color: #003366; color: white; text-align: left;\">Matches</th>\r\n",
    "            </tr>\r\n",
    "        </thead>\r\n",
    "        <tbody>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">#\\S+</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches a hashtag followed by one or more non-whitespace characters.</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">#Python, #AI</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">#Python, #AI</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">[^\\w\\s]</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches any character that is not a word character (\\w) and not whitespace (\\s).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Hello, world!</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">,, !</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">\\d+</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches one or more digits (numbers).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">123, 4567</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">123, 4567</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">\\w+</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches one or more word characters (letters, digits, or underscores).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">hello, world_123</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">hello, world_123</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">\\s+</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches one or more whitespace characters (spaces, tabs, newlines).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Hello world</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">(multiple spaces)</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">^[a-zA-Z]+$</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches a string that contains only alphabetic characters (no spaces, digits, or punctuation).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Python</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Python (matches only alphabetic characters)</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">\\bword\\b</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches the exact word \"word\" (word boundary ensures it's not part of another word).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">word, wordy</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">word (but not wordy)</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">a{2,4}</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches between 2 and 4 consecutive 'a' characters.</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">aa, aaa, aaaa</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">aa, aaa, aaaa</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">[A-Za-z]+</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches one or more alphabetic characters (both lowercase and uppercase).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">hello, WORLD</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">hello, WORLD</td>\r\n",
    "            </tr>\r\n",
    "            <tr>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">[^a-zA-Z0-9]</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">Matches any character that is not a letter or a number (non-alphanumeric characters).</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">@, #, %</td>\r\n",
    "                <td style=\"padding: 12px; text-align: left;\">@, #, %</td>\r\n",
    "            </tr>\r\n",
    "        </tbody>\r\n",
    "    </table>\r\n",
    "</div>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996b2cb8-cbe6-48e7-a285-fce68b1b3b7c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4ce259-20e3-4c18-b4ce-7d5288d9f582",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Task 2: Tokenization</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">Perform tokenization on the cleaned text. Tokenization involves splitting the text into individual words or tokens.</span>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li>1. Break the text into individual words or tokens based on spaces and punctuation marks (such as periods, commas, etc.).</li>\n",
    "        <li>2. Make sure to handle edge cases, such as words joined by hyphens or contractions (e.g., \"don't\", \"it's\").</li>\n",
    "        <li>3. You can use a tokenizer from a Natural Language Processing (NLP) library such as NLTK, SpaCy, or use your own custom implementation.</li>\n",
    "    </ul>\n",
    "    <span style=\"color: #333333;\">After tokenization, you will have a list of words/tokens that can be used for further processing, such as stemming or lemmatization.</span>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5731697d-2bc2-41cd-b230-c7bc05a09f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e24b28a-b2de-47f8-9685-88c28bab155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5dd5cf8-8f0e-4233-9cfd-3d0458a40263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world This Is Mansoor In BS Artificial Intelligence Are you interested in AI "
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59143780-3976-47af-a6b0-c38b98347a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd7ed421-87da-42fb-98dd-6c2d90c36a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Mansoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "248c5745-badb-4aa6-aca8-0f40d5a1bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb75ff16-2660-4dfa-ba9e-3fa6dfdf50eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "him ,they ,during ,can ,now ,ve ,our ,you've ,over ,myself ,off ,than ,y ,that ,whom ,weren't ,don ,or ,its ,before ,through ,in ,ll ,further ,their ,most ,so ,down ,should've ,into ,no ,should ,an ,under ,were ,needn ,been ,hadn ,am ,wouldn ,m ,it's ,hasn ,herself ,until ,too ,ourselves ,have ,s ,wouldn't ,needn't ,ma ,not ,to ,was ,out ,on ,she's ,yours ,here ,don't ,you're ,didn ,them ,ain ,doesn ,shouldn't ,we ,while ,yourself ,d ,of ,these ,hers ,you'll ,themselves ,being ,are ,shan ,you'd ,theirs ,which ,be ,only ,won't ,mustn't ,this ,mightn't ,having ,weren ,other ,himself ,such ,re ,between ,some ,mustn ,won ,do ,it ,once ,wasn ,ours ,how ,own ,shouldn ,you ,his ,haven't ,shan't ,a ,at ,the ,as ,because ,and ,i ,those ,your ,each ,doesn't ,by ,she ,with ,isn't ,up ,is ,nor ,wasn't ,below ,again ,had ,aren't ,very ,hasn't ,if ,didn't ,more ,then ,t ,haven ,itself ,he ,hadn't ,o ,yourselves ,did ,for ,that'll ,mightn ,same ,who ,her ,all ,both ,when ,any ,against ,after ,me ,aren ,isn ,will ,just ,couldn ,why ,has ,from ,what ,few ,about ,couldn't ,does ,there ,my ,where ,doing ,but ,above ,"
     ]
    }
   ],
   "source": [
    "for word in stop_words:\n",
    "    print(word, end=' ,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3246619d-b44d-4a3f-b410-8bc491bd4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a1adbe-d704-45cc-ae24-3c890de800c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world Mansoor BS Artificial Intelligence interested AI "
     ]
    }
   ],
   "source": [
    "for token in filtered_tokens:\n",
    "    print(token, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced5e8dd-416d-4183-b443-d2a726799bbd",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Function For Tokenization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc4fd8c-eb0a-45f6-b261-ed80375e4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    text = preprocess_text(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea8c52-e880-4d39-9354-013971c26948",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Tokenize Text Function</strong>\n",
    "    <br>\n",
    "    <span style=\"color: #333333;\">The <strong>tokenize_text</strong> function performs the following tasks:</span>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li>1. It preprocesses the input text by calling the <strong>preprocess_text</strong> function, which cleans the text (removes punctuation, numbers, etc.).</li>\n",
    "        <li>2. It tokenizes the cleaned text into individual words using <strong>word_tokenize</strong> from NLTK.</li>\n",
    "        <li>3. It removes stopwords (common words like \"the\", \"is\", etc.) using <strong>stopwords.words('english')</strong> from NLTK.</li>\n",
    "        <li>4. It returns a list of filtered tokens, which are words that are not stopwords.</li>\n",
    "    </ul>\n",
    "    <span style=\"color: #333333;\">This function helps in preparing the text for further processing, such as stemming or lemmatization.</span>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f182cc0-43a0-4e29-a87e-67b4ec155de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QUick', 'Brown', 'FOx', 'Jump', 'LAzy', 'Dog']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"A, QUick Brown FOx! Jump over the LAzy Dog. #dog #story\"\n",
    "cleaned_text = tokenize_text(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7f7b2-b482-49be-84bd-257f83ca1701",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b6c19-8c2d-4bce-8b0c-fc2d3eaf2405",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Task 3: Stemming / Lemmatization</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">Perform either stemming or lemmatization on the tokenized text. Both techniques are used to reduce words to their root form, but they differ in their approach:</span>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li><strong>Stemming:</strong> This process removes suffixes from words to obtain the root form. For example, \"running\" becomes \"run\". However, stemming may produce non-existent words (e.g., \"runn\" instead of \"run\").</li>\n",
    "        <li><strong>Lemmatization:</strong> This process reduces words to their base or dictionary form, and it considers the word’s meaning and context (e.g., \"better\" becomes \"good\", and \"running\" becomes \"run\"). Lemmatization usually gives more accurate results but requires a lexicon and may be slower than stemming.</li>\n",
    "    </ul>\n",
    "    <span style=\"color: #333333;\">You can choose either stemming or lemmatization, depending on the accuracy required and the available resources.</span>\n",
    "    <span style=\"color: #333333;\">Once applied, the text will be reduced to its root forms, allowing for more efficient analysis in downstream tasks.</span>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a4849b-4eaa-491e-933b-951008a59f25",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Stemming</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38308b38-fd1d-4ac1-b81a-8bd23088601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f9beee1-aded-4313-97e5-25f638f5e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "158faf74-df3b-4eeb-92d0-248ac09dd658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming Example\n",
    "word = \"running\"\n",
    "stemmed_word = stemmer.stem(word)\n",
    "stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "672c134a-250d-4a36-ac0d-005501bc5518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jump'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'jumping'\n",
    "stemmed_word = stemmer.stem(word)\n",
    "stemmed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe5eacc1-e089-4a0f-9052-8376adc7c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_word = []\n",
    "for text in cleaned_text:\n",
    "    stemmed_word.append(stemmer.stem(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f910242-e06d-4b9f-bd6d-d801492c9fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quick', 'brown', 'fox', 'jump', 'lazi', 'dog']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7aa1d-571d-4936-84d8-f38fe39c3991",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Lemmatization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0535621b-8e9a-4aac-bd08-6a9de3fcc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01098d16-bc6e-4462-9177-f3acfb6e5827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad876652-503e-4081-9321-b451a375f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Mansoor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a9f381-29f1-477f-9084-e2ae35f0d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "word = \"better\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0271fbf-89b9-416b-b385-900684639404",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_word = lemmatizer.lemmatize(word, pos='r')  # Specify part of speech (adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00ba2948-fe49-4616-87ab-04ecc3a24646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "992202ae-5191-499a-a2c5-a9c9db1bc3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_word = []\n",
    "for text in cleaned_text:\n",
    "    lemmatized_word.append(lemmatizer.lemmatize(text, pos='r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65bd12c8-2866-44b0-a538-fce87145b172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QUick', 'Brown', 'FOx', 'Jump', 'LAzy', 'Dog']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d334bdb5-522a-4d0e-b3ae-6f71d6148018",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Function of Stemming and Lemmatization</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d8b3956-11d7-4914-9f86-ef7308188f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer_or_lemmatizer(text, is_stemmer=True, pos=None):\n",
    "    \"\"\"\n",
    "    Applies either stemming or lemmatization to the input text.\n",
    "\n",
    "    Parameters:\n",
    "    - text (str or list): The input text or list of tokens.\n",
    "    - is_stemmer (bool, default=True): If True, uses stemming; if False, uses lemmatization.\n",
    "    - pos (str, optional): Part of speech tag for lemmatization (ignored if is_stemmer=True).\n",
    "    \n",
    "    Returns:\n",
    "    - list: A list of processed tokens.\n",
    "    \"\"\"\n",
    "    text = tokenize_text(text)  # tokenize_text is a function that tokenizes the input text after cleaning it\n",
    "    cleaned_text = []\n",
    "    \n",
    "    if is_stemmer:\n",
    "        # Initialize the stemmer (PorterStemmer)\n",
    "        stemmer = PorterStemmer()\n",
    "        for word in text:\n",
    "            cleaned_text.append(stemmer.stem(word))\n",
    "    else:\n",
    "        # Initialize the lemmatizer (WordNetLemmatizer)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        for word in text:\n",
    "            cleaned_text.append(lemmatizer.lemmatize(word, pos=pos))\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62be11-8514-4961-924d-6fcf121cb7ba",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <span style=\"color: #333333;\">The <strong>stemmer_or_lemmatizer</strong> function applies either stemming or lemmatization to a list of words based on the <strong>is_stemmer</strong> flag:</span>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li>1. If <strong>is_stemmer</strong> is set to <strong>True</strong>, the function uses the <strong>PorterStemmer</strong> to stem each word in the input text.</li>\n",
    "        <li>2. If <strong>is_stemmer</strong> is set to <strong>False</strong>, the function uses the <strong>WordNetLemmatizer</strong> to lemmatize each word. The <strong>pos</strong> parameter (part of speech) can also be provided for more accurate lemmatization.</li>\n",
    "        <li>3. The function returns a list of processed words (either stemmed or lemmatized).</li>\n",
    "    </ul>\n",
    "    <span style=\"color: #333333;\">This function allows you to choose between stemming and lemmatization based on your needs.</span>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35b77aa-a77c-4972-9e48-125dd8eacab8",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <br>\n",
    "    <strong style=\"color: #003366;\">Stemming vs Lemmatization</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">Here is a comparison between Stemming and Lemmatization:</span>\n",
    "    <table style=\"color: #333333; width: 100%; border-collapse: collapse; margin-top: 15px;\">\n",
    "        <tr style=\"background-color: #f2f2f2;\">\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Aspect</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Stemming</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Lemmatization</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Output</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">May produce non-word roots</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Produces valid words (lemmas)</td>\n",
    "        </tr>\n",
    "        <tr style=\"background-color: #f9f9f9;\">\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Accuracy</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Less accurate, may give partial roots</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">More accurate, gives proper words</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Speed</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Faster</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Slower (because it uses lexicons)</td>\n",
    "        </tr>\n",
    "        <tr style=\"background-color: #f9f9f9;\">\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Approach</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Rule-based (heuristic)</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Dictionary-based (lexicon lookup)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Example (Word)</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\"happily\" → \"happi\"</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">\"happily\" → \"happy\"</td>\n",
    "        </tr>\n",
    "        <tr style=\"background-color: #f9f9f9;\">\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Context Awareness</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">No, doesn’t consider POS</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Yes, considers context (e.g., verb, noun)</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72764582-6d61-49d4-96cf-e446ad897ead",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef0bc3-4695-4b82-9031-d745b0a97205",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Test Working</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a586fc93-df59-4486-a948-84542760144e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['quick', 'jump', 'lazi', 'dog']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test strings for preprocessing pipeline\n",
    "test_string_1 = \"The quick #foxes are jumping over the lazy dogs 123!\"\n",
    "process_test_1 = stemmer_or_lemmatizer(test_string_1)\n",
    "process_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8fdc4c7-f796-403d-b876-b47de6f2be15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happili', 'run', 'toward', 'store']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string_2 = \"She was happily running towards the store. #excited\"\n",
    "process_test_2 = stemmer_or_lemmatizer(test_string_2)\n",
    "process_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af6d83a5-da2e-43fb-83af-7acceb04db22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happily', 'run', 'towards', 'store']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_test_2 = stemmer_or_lemmatizer(test_string_2,is_stemmer=False, pos='v')\n",
    "process_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3643fbbf-6450-4b86-8f13-0898afde4c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['study', 'intensely', 'exam']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string_3 = \"He has been studying intensely for the exam. #studyTime\"\n",
    "process_test_3 = stemmer_or_lemmatizer(test_string_3,is_stemmer=False, pos='v')\n",
    "process_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72687b5e-a123-4d30-af02-140f0be444ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'play', 'garden', 'day', 'PM']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string_4 = \"The cats were playing in the garden all day, at 9 PM.\"\n",
    "process_test_4 = stemmer_or_lemmatizer(test_string_4,is_stemmer=False, pos='v')\n",
    "process_test_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "990adfa1-7a66-4768-be9b-33fd98de4cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learn', 'new', 'concepts', 'every', 'day', 'class']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string_5 = \"We are learning new concepts every day in class. #Learning\"\n",
    "process_test_5 = stemmer_or_lemmatizer(test_string_5,is_stemmer=False, pos='v')\n",
    "process_test_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e60ed-7559-4b60-b9b7-44f16663781e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">POS (Part-of-Speech) Parameter Values for WordNetLemmatizer</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">The following table shows the different POS (Part-of-Speech) parameter values that can be used with the <strong>WordNetLemmatizer</strong> function:</span>\n",
    "    <table style=\"color: #333333; width: 100%; border-collapse: collapse; margin-top: 15px;\">\n",
    "        <tr style=\"background-color: #f2f2f2;\">\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">POS Value</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Meaning</th>\n",
    "            <th style=\"border: 1px solid #ddd; padding: 8px;\">Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">'n'</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Noun</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">dog, tree</td>\n",
    "        </tr>\n",
    "        <tr style=\"background-color: #f9f9f9;\">\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">'v'</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Verb</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">run, jump</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">'a'</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Adjective</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">happy, big</td>\n",
    "        </tr>\n",
    "        <tr style=\"background-color: #f9f9f9;\">\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">'r'</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Adverb</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">quickly, slowly</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">'s'</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Possessive pronoun</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">his, her</td>\n",
    "        </tr>\n",
    "        <tr style=\"background-color: #f9f9f9;\">\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">'t'</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">Particle</td>\n",
    "            <td style=\"border: 1px solid #ddd; padding: 8px;\">not, up</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "    <span style=\"color: #333333;\">These POS tags help the lemmatizer understand the context of the word, which improves the accuracy of lemmatization.</span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
