{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7fb95c9-4020-4517-8c66-eae394fb28cd",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ffcc00; background-color: #2a2a2a; padding: 30px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    Natural Language Processing\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ff9900; background-color: #333333; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    Lab 02\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ff6600; background-color: #1c1c1c; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    Syed Mansoor ul Hassan Bukhari\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ffcc00; background-color: #222222; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3); margin-bottom: 20px;\">\n",
    "    BSAI - VII\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #ff3300; background-color: #1c1c1c; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\">\n",
    "    2021-25\n",
    "</div>\n",
    "\n",
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 48px; font-weight: bold; text-align: center; color: #3399ff; background-color: #1c1c1c; padding: 20px; border: 3px solid #444; border-radius: 15px; box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);\">\n",
    "    <span style=\"position: relative; top: -10px;\">26</span> Jan, 2025\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76bce6-8745-4abc-8de0-536ef8e2144c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <br>\n",
    "    <strong style=\"color: #003366;\">Task 1: Load and Preview Dataset</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">Remove the following elements from the input text:</span>\n",
    "    <span style=\"color: #333333;\">Pandas is used to load dataset through <span style='color:#003366'>read_csv()</span> function and we preview it through <span style='color:#003366'>head()</span></span>\n",
    "    <br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56d679e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cafa2e-4e1d-4811-a632-0445f20500ff",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <br>\n",
    "    <strong style=\"color: #003366;\">Task 2: Data Cleaning</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">Remove the following elements from the input data:</span>\n",
    "    <ul style=\"color: #333333;\">\n",
    "        <li>1. textID </li>\n",
    "        <li>2. selected_text</li>\n",
    "    </ul>\n",
    "    <span style=\"color: #333333;\">We use <span style='color:#003366'>drop()</span> function from  <span style='color:#003366'>pd</span> to drop it.</span>\n",
    "    <br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd0abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['textID', 'selected_text'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0e6704-2f8f-4e03-9628-63c7b6d9d0ea",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: left; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <br>\n",
    "    <strong style=\"color: #003366;\">Task 3: Preprocessing: tokenization and cleaning</strong>\n",
    "    <br><br>\n",
    "    <span style=\"color: #333333;\">We preprocess our data and tokenize it. Then we create vocabulary and class frequencies</span>\n",
    "    <br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b78575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c73a90-53f1-4c24-b932-e91c3d3a7e7c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Create vocabulary and class frequencies </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20366009",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "class_counts = defaultdict(int)\n",
    "word_counts = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44e55e3-4027-4655-8964-848f053b4c10",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Populate word and class counts from training data</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iterrows():\n",
    "    sentence = row['text']\n",
    "    sentiment = row['sentiment']\n",
    "    \n",
    "    # include \"positive\" and \"negative\" sentiments for classification\n",
    "    if sentiment in ['positive', 'negative']:\n",
    "        words = preprocess_text(sentence)\n",
    "        class_counts[sentiment] += 1\n",
    "        for word in words:\n",
    "            word_counts[sentiment][word] += 1\n",
    "            vocab.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f325abc-6a43-4bf3-ae54-b5c8c181230a",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\"> Compute prior probabilities</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36914539",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sentences = len(df)\n",
    "prior_prob = {label: count / total_sentences for label, count in class_counts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d03780d-19ca-47d3-8552-f6f01668742c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Compute likelihood with add-1 smoothing </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cfa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = defaultdict(lambda: defaultdict(float))\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ab2488",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in class_counts:\n",
    "    total_words_in_class = sum(word_counts[label].values())\n",
    "    for word in vocab:\n",
    "        # Add-1 smoothing\n",
    "        likelihoods[label][word] = (word_counts[label][word] + 1) / (total_words_in_class + vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ff13a-0f8e-4015-91ad-04084dda4776",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Define function to classify new sentences </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    words = preprocess_text(sentence)\n",
    "    posterior_prob = {}\n",
    "    \n",
    "    for label in class_counts:\n",
    "        log_prob = math.log(prior_prob[label])  # Start with log(prior)\n",
    "        for word in words:\n",
    "            log_prob += math.log(likelihoods[label].get(word, 1 / (sum(word_counts[label].values()) + vocab_size)))\n",
    "        posterior_prob[label] = log_prob\n",
    "    \n",
    "    # Classify the sentence based on maximum posterior probability\n",
    "    return max(posterior_prob, key=posterior_prob.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ef46a3-cff6-4d0f-bd50-00f711f5cbb0",
   "metadata": {},
   "source": [
    "<div style=\"font-family: 'Arial', sans-serif; font-size: 20px; text-align: center; color: #000000; background-color: #f4f4f4; padding: 25px; border: 3px solid #555555; border-radius: 15px; box-shadow: 0 6px 15px rgba(0, 0, 0, 0.4); margin-bottom: 25px;\">\n",
    "    <strong style=\"color: #003366;\">Predict</strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44090e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = classify_sentence(\"This product is excellent and not bad\")  # Calls classify_sentence() for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2650e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
